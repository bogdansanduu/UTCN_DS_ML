{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Data Processing and Analysis\n",
    "\n",
    "In this section, we will load, analyze, and process data for polynomial regression. It's important to note that we are working with one-dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file):\n",
    "\n",
    "    x, y = None, None\n",
    "\n",
    "    data = np.load(file)\n",
    "    x, y = data\n",
    "    y = y / 1000\n",
    "\n",
    "    return x, y\n",
    "\n",
    "x, y = load_dataset(\"data.npy\")\n",
    "\n",
    "# Plot the loaded data to verify\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x, y, label=\"Loaded Data Points\", alpha=0.7)\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(\"Loaded Polynomial Data\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, validation and testing sets\n",
    "# Input: X - the input examples\n",
    "#        y - the output labels\n",
    "#        percentage_test - the percentage of data to be used for testing\n",
    "#        percentage_validation - the percentage of data to be used for validation\n",
    "# Output: X_train - the input examples for the training set\n",
    "#         y_train - the output labels for the training set\n",
    "#         X_val - the input examples for the validation set\n",
    "#         y_val - the output labels for the validation set\n",
    "#         X_test - the input examples for the testing set\n",
    "#         y_test - the output labels for the testing set\n",
    "# Hint: Don't forget to shuffle the data\n",
    "\n",
    "def split_data(X, y, percentage_test=0.1, percentage_validation=0.1):\n",
    "\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = None, None, None, None\n",
    "    num_samples = None\n",
    "\n",
    "    ########## Your code goes here ##########\n",
    "\n",
    "    \n",
    "\n",
    "    #########################################\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n",
    "# Normalize the data\n",
    "# Input: X - the input examples\n",
    "#        mean - the mean of the input examples\n",
    "#        std - the standard deviation of the input examples\n",
    "# Output: X - the normalized input examples\n",
    "def normalize(X, mean=None, std=None):\n",
    "   \n",
    "    ########## Your code goes here ##########\n",
    "\n",
    "\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    return X\n",
    "\n",
    "# Preprocess the data end to end\n",
    "# Steps:\n",
    "# 2. Load the data\n",
    "# 3. Split the data into training, validation and testing sets\n",
    "# 4. Normalize the data\n",
    "# 5. Return the preprocessed data\n",
    "# Input: X - the input examples\n",
    "#        y - the output labels\n",
    "#        percentage_test - the percentage of data to be used for testing\n",
    "#        percentage_validation - the percentage of data to be used for validation\n",
    "# Output: X_train - the input examples for the training set\n",
    "#         y_train - the output labels for the training set\n",
    "#         X_val - the input examples for the validation set\n",
    "#         y_val - the output labels for the validation set\n",
    "#         X_test - the input examples for the testing set\n",
    "#         y_test - the output labels for the testing set\n",
    "\n",
    "def prepocess_data(X, y, percentage_test=0.1, percentage_validation=0.1):\n",
    "\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = None, None, None, None, None, None\n",
    "\n",
    "    ########## Your code goes here ##########\n",
    "\n",
    "   \n",
    "    #########################################\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = prepocess_data(x, y)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_train, y_train, label=\"Train Data Points\", alpha=0.7)\n",
    "plt.scatter(X_val, y_val, label=\"Validation Data Points\", alpha=0.7)\n",
    "plt.scatter(X_test, y_test, label=\"Test Data Points\", alpha=0.7)\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(\"Polynomial Data Split\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Implementation\n",
    "\n",
    "In this section, we will implement the hypothesis, loss function, and evaluation metric. Our implementation will be modular, allowing us to run multiple experiments to observe the impact of different hyperparameter choices, namely the regularization strength and the polynomial degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a set of features X, create polynomial features up to degree\n",
    "# Input: X - the input examples\n",
    "#        degree - the maximum degree of the polynomial\n",
    "# Output: X_poly - the polynomial features as a numpy array of shape (no_examples, degree+1)\n",
    "# Hint: Use np.hstack to add columns to the matrix\n",
    "#       Don't forget the bias term (x^0)\n",
    "#       You may need to reshape X from a 1D array to a 2D array\n",
    "\n",
    "def polynomial_features(X, degree):\n",
    "\n",
    "    X_poly = None\n",
    "\n",
    "    ############## Your code here #############\n",
    "\n",
    "    \n",
    "    #########################################\n",
    "\n",
    "    return X_poly\n",
    "\n",
    "# Given the data X and the weight vector w, compute the predictions\n",
    "# Input: X - the input examples\n",
    "#        w - the weight vector\n",
    "#        degree - the maximum degree of the polynomial\n",
    "# Output: y_pred - the predicted output\n",
    "# Hint: Use the polynomial_features function you implemented in the previous task\n",
    "#       The prediction operation is similar to the one in linear regression\n",
    "\n",
    "def predict(X, w, degree):\n",
    "\n",
    "    y_pred = None \n",
    "\n",
    "    ############## Your code here #############\n",
    "\n",
    "\n",
    "\n",
    "    ###########################################\n",
    "\n",
    "    return y_pred   \n",
    "\n",
    "# Given the data X, the labels y and the weight vector w, compute the MSE loss  \n",
    "# Input: X - the input examples\n",
    "#        y - the output labels\n",
    "#        w - the weight vector\n",
    "#        regularization_strength - the regularization strength\n",
    "# Output: mse - the mean squared error loss\n",
    "\n",
    "\n",
    "def MSE(y_pred, y, w, regularization_strength=0):\n",
    "\n",
    "    mse_loss = None\n",
    "\n",
    "    ############## Your code here #############\n",
    "\n",
    "\n",
    "\n",
    "    ###########################################\n",
    "\n",
    "    return mse_loss\n",
    "\n",
    "# Given the data X, the labels y, predicted values y_pred and the weight vector w, compute the gradient of the loss\n",
    "# Input: X - the input examples\n",
    "#        y - the output labels\n",
    "#        y_pred - the predicted output\n",
    "#        w - the weight vector\n",
    "#        regularization_strength - the regularization strength\n",
    "#        degree - the maximum degree of the polynomial\n",
    "# Output: gradient - the gradient of the loss with respect to the weight vector\n",
    "# Hint: Use the polynomial_features function you implemented in the previous task\n",
    "#       Don't forget the regularization term in the gradient computation\n",
    "#       The gradient computation is similar to the one in linear regression for vecotrized implementation\n",
    "def gradient(X, y, y_pred, w, regularization_strength, degree):\n",
    "\n",
    "    gradient = None\n",
    "\n",
    "    ############## Your code here #############\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ###########################################\n",
    "\n",
    "    return gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the train function, which will train a polynomial regression model\n",
    "# Input: X_train - the input examples for the training set\n",
    "#        y_train - the output labels for the training set\n",
    "#        X_val - the input examples for the validation set\n",
    "#        y_val - the output labels for the validation set\n",
    "#        regularization_strength - the regularization strength\n",
    "#        polynomial_degree - the maximum degree of the polynomial\n",
    "#        learning_rate - the learning rate\n",
    "#        iterations - the number of iterations\n",
    "# Output: w - the weight vector learned\n",
    "#        losses_train - the training loss at each iteration\n",
    "#        mse_train - the training mse at each iteration\n",
    "#        loss_val - the validation loss at each iteration\n",
    "#        mse_val - the validation mse at each iteration\n",
    "# Hint: Initialize the weights randomly\n",
    "#       We save both losses with regularization as well as without regularization because we want to interpret the metric on the test set at the end\n",
    "#       The loss and mse are calculated using the MSE function you implemented MSE will set the regularization_strength to 0\n",
    "\n",
    "def train(X_train, y_train, X_val, y_val, regularization_strength, polynomial_degree, learning_rate, iterations):\n",
    "  \n",
    "    w, losses_train, mse_train, loss_val, mse_val = None, [], [], [], []\n",
    "\n",
    "    ############## Your code here #############\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ###########################################\n",
    "\n",
    "    return w, losses_train, mse_train, loss_val, mse_val\n",
    "\n",
    "# Implement the test function, which will evaluate the polynomial regression model\n",
    "# Input: X_test - the input examples for the testing set\n",
    "#        y_test - the output labels for the testing set\n",
    "#        w - the learned weight vector\n",
    "#        degree - the maximum degree of the polynomial\n",
    "# Output: y_pred - the predicted output\n",
    "#         mse - the mean squared error loss\n",
    "\n",
    "def test(X_test, y_test, w, degree):\n",
    "\n",
    "    y_pred, mse = None, None\n",
    "    \n",
    "    ############## Your code here #############\n",
    "\n",
    "\n",
    "    ###########################################\n",
    "\n",
    "    return y_pred, mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Experiments\n",
    "\n",
    "Run the following experiments: \n",
    "\n",
    "polynomial rregression with degree 1, 2, 3, 7\n",
    "with the following regularization strngts 0., 0.2, 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 7\n",
    "regularization_strength = 0.\n",
    "learning_rate = 0.001\n",
    "iterations = 1000\n",
    "\n",
    "w, losses_train, mse_train, loss_val, mse_val = train(X_train, y_train, X_val, y_val, regularization_strength, degree, learning_rate, iterations)\n",
    "\n",
    "# predict each value from -1.5 to 1.5\n",
    "X_pred_continous = np.linspace(-1.7, 1.7, 10000)\n",
    "y_pred_continous = predict(X_pred_continous, w, degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_train, y_train, label=\"Train Data Points\", alpha=0.7)\n",
    "plt.scatter(X_val, y_val, label=\"Validation Data Points\", alpha=0.7)\n",
    "plt.scatter(X_pred_continous, y_pred_continous, label=\"Model\", alpha=0.7)\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(\"Display polynomial model on train and validation data\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation loss but only the first 100 iterations\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(losses_train[:50], label=\"Train Loss\")\n",
    "plt.plot(loss_val[:50], label=\"Validation Loss\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss vs Iterations\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test your best result\n",
    "\n",
    "When you feel confident of your model performance evaluate it on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred_test, mse_test = test(X_test, y_test, w, degree)\n",
    "print(f\"Test MSE: {mse_test}\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_train, y_train, label=\"Train Data Points\", alpha=0.7)\n",
    "plt.scatter(X_val, y_val, label=\"Validation Data Points\", alpha=0.7)\n",
    "plt.scatter(X_test, y_test, label=\"Test Data Points\", alpha=0.7)\n",
    "plt.scatter(X_pred_continous, y_pred_continous, label=\"Model\", alpha=0.7)\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(\"Display polynomial model on train, validation and test data\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
