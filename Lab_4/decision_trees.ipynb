{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "from collections import Counter\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('skiing_data.npz')\n",
    "X = data['X']\n",
    "y = data['y']\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=\"coolwarm\", edgecolor=\"k\")\n",
    "plt.xlabel(\"Latitude\")\n",
    "plt.ylabel(\"Month\")\n",
    "plt.title(\"Decision Boundary of the Decision Tree\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None, criterion=\"gini\"):\n",
    "        self.max_depth = max_depth\n",
    "        self.criterion = criterion\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tree = self.grow_tree(X, y)\n",
    "\n",
    "    def grow_tree(self, X, y, depth=0):\n",
    "        num_samples, num_features = X.shape\n",
    "        num_labels = len(set(y))\n",
    "\n",
    "        # regularization - stop if max_depth is reached or if there is only one label\n",
    "        if (depth >= self.max_depth or num_labels == 1):\n",
    "            return {\"label\": Counter(y).most_common(1)[0][0]}\n",
    "        \n",
    "        best_split = self.best_split(X, y, num_features)\n",
    "\n",
    "        if best_split[\"gain\"] == 0:\n",
    "            return {\"label\": Counter(y).most_common(1)[0][0]}\n",
    "\n",
    "        left = self.grow_tree(best_split[\"X_left\"], best_split[\"y_left\"], depth + 1)\n",
    "        right = self.grow_tree(best_split[\"X_right\"], best_split[\"y_right\"], depth + 1)\n",
    "\n",
    "        return {\n",
    "            \"feature\": best_split[\"feature\"],\n",
    "            \"threshold\": best_split[\"threshold\"],\n",
    "            \"left\": left,\n",
    "            \"right\": right,\n",
    "        }\n",
    "\n",
    "    # Find the best split for the current node in the tree with respect to one feature\n",
    "    # input: X, y, num_features\n",
    "    # output: split -> dictionary containing the feature, threshold, gain, X_left, y_left, X_right, y_right\n",
    "    def best_split(self, X, y, num_features):\n",
    "\n",
    "        best_gain = -1\n",
    "        feature, threshold, gain, X_left, X_right, y_left, y_right = None, None, None , None, None, None, None\n",
    "        split = {\n",
    "            \"feature\": feature,\n",
    "            \"threshold\": threshold,\n",
    "            \"gain\": gain,\n",
    "            \"X_left\": X_left,\n",
    "            \"y_left\": y_left,\n",
    "            \"X_right\": X_right,\n",
    "            \"y_right\": y_right,\n",
    "        }\n",
    "        \n",
    "        ########## Your code goes here ##########\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ###########################################\n",
    "\n",
    "        return split\n",
    "\n",
    "    # split the data into two regions based on the feature and threshold and computes the information gain\n",
    "    def split(self, X, y, feature, threshold):\n",
    "        left_idx = X[:, feature] <= threshold\n",
    "        right_idx = X[:, feature] > threshold\n",
    "        X_left, y_left = X[left_idx], y[left_idx]\n",
    "        X_right, y_right = X[right_idx], y[right_idx]\n",
    "\n",
    "        if len(y_left) == 0 or len(y_right) == 0:\n",
    "            return 0, X_left, y_left, X_right, y_right\n",
    "\n",
    "        gain = self.information_gain(y, y_left, y_right)\n",
    "\n",
    "        return gain, X_left, y_left, X_right, y_right\n",
    "\n",
    "    # Compute the information gain\n",
    "    # Note that you must weight the left and right child nodes by the number of samples in each\n",
    "    def information_gain(self, y, y_left, y_right):\n",
    "\n",
    "        gain = None\n",
    "\n",
    "        ########## Your code goes here ##########\n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ###########################################\n",
    "\n",
    "        return gain\n",
    "\n",
    "    # Compute the gini impurity\n",
    "    def gini(self, y):\n",
    "\n",
    "        gini_impurity = None\n",
    "\n",
    "        ########## Your code goes here ##########\n",
    "       \n",
    "\n",
    "\n",
    "        ###########################################\n",
    "\n",
    "        return gini_impurity\n",
    "\n",
    "    # Compute the entropy\n",
    "    def entropy(self, y):\n",
    "\n",
    "        entropy_value = None\n",
    "\n",
    "        ########## Your code goes here ##########\n",
    "\n",
    "\n",
    "\n",
    "        ###########################################\n",
    "\n",
    "        return entropy_value\n",
    "    \n",
    "    # Predict for a vector of inputs\n",
    "    def predict(self, X):\n",
    "        return np.array([self.predict_single(inputs, self.tree) for inputs in X])\n",
    "\n",
    "    # Predict for a single input\n",
    "    def predict_single(self, inputs, tree):\n",
    "        if \"label\" in tree:\n",
    "            return tree[\"label\"]\n",
    "        feature = tree[\"feature\"]\n",
    "        threshold = tree[\"threshold\"]\n",
    "        if inputs[feature] <= threshold:\n",
    "            return self.predict_single(inputs, tree[\"left\"])\n",
    "        else:\n",
    "            return self.predict_single(inputs, tree[\"right\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "\n",
    "def get_tree_depth(tree):\n",
    "    if \"label\" in tree:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 + max(get_tree_depth(tree[\"left\"]), get_tree_depth(tree[\"right\"]))\n",
    "\n",
    "def plot_tree(tree, depth=0, ax=None, pos=(0, 0), layer_spacing=8, depth_spacing=1.5, tree_depth=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(25, 10))\n",
    "    \n",
    "    if \"label\" in tree:\n",
    "        ax.text(pos[0], pos[1], f'Class: {tree[\"label\"]}', ha='center', va='center',\n",
    "                bbox=dict(facecolor='lightblue', edgecolor='black'))\n",
    "    else:\n",
    "        feature, threshold = tree[\"feature\"], tree[\"threshold\"]\n",
    "        text = f\"X[{feature}] <= {threshold}\"\n",
    "        ax.text(pos[0], pos[1], text, ha='center', va='center',\n",
    "                bbox=dict(facecolor='lightgreen', edgecolor='black'))\n",
    "\n",
    "        # Left child\n",
    "        left_pos = (pos[0] - layer_spacing / 2 ** (depth + 1), pos[1] - depth_spacing)\n",
    "        arrow_left = FancyArrowPatch(posA=pos, posB=left_pos, arrowstyle='-|>', mutation_scale=10,\n",
    "                                     color='k', lw=1)\n",
    "        ax.add_patch(arrow_left)\n",
    "        plot_tree(tree[\"left\"], depth + 1, ax, left_pos, layer_spacing, depth_spacing, tree_depth)\n",
    "\n",
    "        # Right child\n",
    "        right_pos = (pos[0] + layer_spacing / 2 ** (depth + 1), pos[1] - depth_spacing)\n",
    "        arrow_right = FancyArrowPatch(posA=pos, posB=right_pos, arrowstyle='-|>', mutation_scale=10,\n",
    "                                      color='k', lw=1)\n",
    "        ax.add_patch(arrow_right)\n",
    "        plot_tree(tree[\"right\"], depth + 1, ax, right_pos, layer_spacing, depth_spacing, tree_depth)\n",
    "\n",
    "    if depth == 0:\n",
    "        ax.set_xlim(-layer_spacing, layer_spacing)\n",
    "        ax.set_ylim(-depth_spacing * (tree_depth + 1), 1)\n",
    "        ax.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "# Assuming you have a DecisionTree class with a 'tree' attribute\n",
    "# and 'X' and 'y' are your data and labels.\n",
    "tree = DecisionTree(max_depth=5, criterion=\"gini\")\n",
    "tree.fit(X, y)\n",
    "\n",
    "# Calculate the maximum depth of the tree\n",
    "tree_depth = get_tree_depth(tree.tree)\n",
    "plot_tree(tree.tree, layer_spacing=8, depth_spacing=1.5, tree_depth=tree_depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundaries(tree, X, y):\n",
    "    # Define bounds of the plot\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    \n",
    "    # Create a grid of points with a small step\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                         np.arange(y_min, y_max, 0.01))\n",
    "    \n",
    "    # Use the classifier to predict the class at each grid point\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "    Z = tree.predict(grid)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Plot the contours\n",
    "    plt.contourf(xx, yy, Z, alpha=0.3, cmap=\"coolwarm\")\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=\"coolwarm\", edgecolor=\"k\")\n",
    "    plt.xlabel(\"Latitude\")\n",
    "    plt.ylabel(\"Month\")\n",
    "    plt.title(\"Decision Boundary of the Decision Tree\")\n",
    "    plt.show()\n",
    "\n",
    "plot_decision_boundaries(tree, X, y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
